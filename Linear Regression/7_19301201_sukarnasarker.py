# -*- coding: utf-8 -*-
"""7_19301201_SukarnaSarker.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1jtoEtcpF09KRwMgYOm7fgYwy3m7aYps2
"""

import numpy as np
import pandas as pd
import sklearn
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn import datasets, preprocessing, linear_model
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from sklearn.metrics import classification_report
from sklearn.metrics import accuracy_score
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import accuracy_score
import matplotlib.pyplot as plot

df = pd.read_csv("/content/Income Dataset (50k).csv")
df = df.drop(["workclass","occupation","native-country"],axis=1)
enc = LabelEncoder()
df["education"]=enc.fit_transform(df["education"])
df["marital-status"]=enc.fit_transform(df["marital-status"])
df["relationship"]=enc.fit_transform(df["relationship"])
df["race"]=enc.fit_transform(df["race"])
df["gender"]=enc.fit_transform(df["gender"])
X = df.values
Y = df['gender'].values
X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.20, random_state=100)

regr = LogisticRegression()
regr.fit(X_train, Y_train)
LP = regr.predict(X_test)
percentage1=accuracy_score(Y_test, LP)
p1=percentage1*100
round1=round(p1,3)
print ("Accuracy using logistic regression=",round1,"%")

tree = DecisionTreeClassifier(criterion='entropy', random_state=100)
tree.fit(X_train,Y_train)
predict1 = tree.predict(X_test)
percentage2=accuracy_score(predict1,Y_test)
p2=percentage2*100
round2 = round(p2,1)
print("Accuracy using decision tree=",round2,"%")

label1 = ['Logistic Regression', 'Decision Tree']
Percentage = [accuracy_score(Y_test, LP), accuracy_score(predict1,Y_test)]
plot.bar(label1, Percentage)
plot.title('income')
plot.ylabel('accuracy')
plot.show()